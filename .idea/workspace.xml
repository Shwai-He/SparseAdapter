<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="SELECTIVE" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="3bc0cb99-659d-4909-9954-7a791d56dc66" name="Changes" comment="">
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="FlaskConsoleOptions" custom-start-script="import sys&#10;sys.path.extend([WORKING_DIR_AND_PYTHON_PATHS])&#10;from flask.cli import ScriptInfo&#10;locals().update(ScriptInfo(create_app=None).load_app().make_shell_context())&#10;print(&quot;Python %s on %s\nApp: %s [%s]\nInstance: %s&quot; % (sys.version, sys.platform, app.import_name, app.env, app.instance_path))">
    <envs>
      <env key="FLASK_APP" value="app" />
    </envs>
    <option name="myCustomStartScript" value="import sys&#10;sys.path.extend([WORKING_DIR_AND_PYTHON_PATHS])&#10;from flask.cli import ScriptInfo&#10;locals().update(ScriptInfo(create_app=None).load_app().make_shell_context())&#10;print(&quot;Python %s on %s\nApp: %s [%s]\nInstance: %s&quot; % (sys.version, sys.platform, app.import_name, app.env, app.instance_path))" />
    <option name="myEnvs">
      <map>
        <entry key="FLASK_APP" value="app" />
      </map>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="GitSEFilterConfiguration">
    <file-type-list>
      <filtered-out-file-type name="LOCAL_BRANCH" />
      <filtered-out-file-type name="REMOTE_BRANCH" />
      <filtered-out-file-type name="TAG" />
      <filtered-out-file-type name="COMMIT_BY_MESSAGE" />
    </file-type-list>
  </component>
  <component name="MarkdownSettingsMigration">
    <option name="stateVersion" value="1" />
  </component>
  <component name="ProjectId" id="269MSsJalNhlPrnp7MpBJQH4dfE" />
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">
    <property name="RunOnceActivity.OpenProjectViewOnStart" value="true" />
    <property name="RunOnceActivity.ShowReadmeOnStart" value="true" />
    <property name="WebServerToolWindowFactoryState" value="true" />
    <property name="credentialsType com.jetbrains.python.remote.PyCreateRemoteInterpreterDialog$PyCreateRemoteSdkForm" value="Web Deployment" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$/../Exploration/LLAMA" />
    <property name="node.js.detected.package.eslint" value="true" />
    <property name="node.js.detected.package.tslint" value="true" />
    <property name="node.js.selected.package.eslint" value="(autodetect)" />
    <property name="node.js.selected.package.tslint" value="(autodetect)" />
    <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable" />
    <property name="two.files.diff.last.used.folder" value="$PROJECT_DIR$/examples/pytorch/text-classification" />
  </component>
  <component name="RecentsManager">
    <key name="CopyFile.RECENT_KEYS">
      <recent name="D:\heshuai36\Project\unify-parameter-efficient-tuning-master\examples\pytorch\question-answering" />
    </key>
    <key name="MoveFile.RECENT_KEYS">
      <recent name="E:\Project\SparseAdapter\examples\pytorch\question-answering" />
      <recent name="D:\heshuai36\Project\unify-parameter-efficient-tuning-master\examples\pytorch\question-answering" />
    </key>
  </component>
  <component name="RunManager" selected="Python.run_qa (1)">
    <configuration name="launch_glue" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10088/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/distributed/launch.py" />
      <option name="PARAMETERS" value="--master_port 12482 --nproc_per_node 1 /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/run_glue_pruned.py --model_name_or_path roberta-base --task_name mnli --do_train yes --do_eval yes --max_seq_length 128 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --max_tokens_per_batch 0 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode adapter --attn_option sequential --attn_composition add --attn_bn 256 --ffn_mode adapter --ffn_option sequential --ffn_adapter_layernorm_option none --ffn_adapter_scalar 1 --ffn_adapter_init_option bert --ffn_bn 256 --mid_dim 800 --seed 42 --unfreeze_params ef_ --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 10 --learning_rate 1e-4 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_steps 0 --warmup_ratio 0.06 --max_seq_length 512 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 0.5_1._adapter_256_adapter_256 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model accuracy --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/checkpoints/glue/mnli/20220430/snip_0.5_1._adapter_sequential_256_adapter_sequential_256 --pruner snip --prune_epochs 10 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 0.5 --attn_sparsity 1. --device_ids &quot;0 1 2 3&quot; --dataloader_num_workers 8" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="launch_glue" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10090/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/distributed" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/distributed/launch.py" />
      <option name="PARAMETERS" value="--master_port 10988 --nproc_per_node 1 /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/run_glue_pruned.py --model_name_or_path bert-base-cased --begin 0 --prune_iterations 1 --task_name stsb --do_train yes --do_eval yes --max_seq_length 128 --per_device_train_batch_size 48 --per_device_eval_batch_size 48 --max_tokens_per_batch 0 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode adapter --attn_option sequential --attn_composition add --attn_bn 64 --ffn_mode adapter --ffn_option sequential --ffn_adapter_layernorm_option none --ffn_adapter_scalar 2 --ffn_adapter_init_option lora --ffn_bn 64 --mid_dim 800 --seed 42 --unfreeze_params ef_ --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 20 --learning_rate 1e-4 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_steps 0 --warmup_ratio 0.06 --max_seq_length 512 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 0.6_adapter_64_adapter_64 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model pearson --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/bert/checkpoints/bert-base-cased/stsb/20220601/grasp_0.6_0_1_adapter_sequential_64_adapter_sequential_64 --pruner grasp --prune_epochs 10 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 0.6 --device_ids &quot;0 1&quot; --dataloader_num_workers 16" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="launch_lm" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10088/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/distributed" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/distributed/launch.py" />
      <option name="PARAMETERS" value="--master_port 1232 --nproc_per_node 1 /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/language-modeling/run_clm_split.py --model_name_or_path gpt2 --dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train True --do_eval True --do_predict True --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/language-modeling/checkpoints/gpt2moe --overwrite_output_dir --device_ids &quot;4 5 6 7&quot; --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/language-modeling/huggingface/datasets --use_moe True --num_train_epochs 6 --evaluation_strategy epoch --save_strategy epoch --save_steps 500 --eval_steps 500 --sparsity 0.5 --pruner rand --use_moe True" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="resume" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10092/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/text-classification" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\text-classification\run_glue_sparse.py" />
      <option name="PARAMETERS" value="--model_name_or_path bert-base-cased --task_name sst2 --do_train False --do_eval yes --max_seq_length 128 --per_device_train_batch_size 48 --per_device_eval_batch_size 48 --max_tokens_per_batch 0 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode adapter --attn_option sequential --attn_composition add --attn_bn 1024 --ffn_mode adapter --ffn_option sequential --ffn_adapter_layernorm_option none --ffn_adapter_scalar 1 --ffn_adapter_init_option bert --ffn_bn 1024 --mid_dim 800 --seed 42 --unfreeze_params ef_ --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 10 --learning_rate 1e-4 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_ratio 0.06 --max_seq_length 512 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 1._adapter_1024_adapter_1024 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model accuracy --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/bert/checkpoints/rte/20220526/snip_1._adapter_sequential_128_adapter_sequential_128 --pruner snip --prune_epochs 1 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 1. --device_ids &quot;0&quot; --dataloader_num_workers 2 --resume_from_checkpoint /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/bert/checkpoints/bert-base-cased/sst2/20220524/snip_1._adapter_sequential_1024_adapter_sequential_1024" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_glue" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/text-classification" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py" />
      <option name="PARAMETERS" value="--model_name_or_path roberta-base --output_dir /user/sunsiqi/hs/SparseAdapter/examples/pytorch/text-classification/unstructured/roberta --task_name rte --do_train yes --overwrite_output_dir" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_glue_bert" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10092/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/language-modeling" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="false" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\text-classification\run_glue_sparse.py" />
      <option name="PARAMETERS" value="--model_name_or_path bert-base-uncased --begin 0 --prune_iterations 1 --task_name cola --mask_scope local --do_train False --do_eval yes --max_seq_length 128 --per_device_train_batch_size 48 --per_device_eval_batch_size 48 --max_tokens_per_batch 0 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode adapter --attn_option sequential --attn_composition add --attn_bn 64 --ffn_mode adapter --ffn_option sequential --ffn_adapter_layernorm_option none --ffn_adapter_scalar 2 --ffn_adapter_init_option bert --ffn_bn 64 --mid_dim 800 --seed 42 --unfreeze_params LayerNorm --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 20 --learning_rate 1e-4 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_steps 0 --warmup_ratio 0.06 --max_seq_length 128 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 0.6_adapter_64_adapter_64 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model accuracy --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/bert/checkpoints/bert-base-cased/mrpc/20220609/snip_0.6_0_1_adapter_sequential_64_adapter_sequential_64 --pruner snip --prune_epochs 1 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 1. --device_ids &quot;0 1 2 3 4 5 6 7&quot; --dataloader_num_workers 16 --resume_from_checkpoint /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/bert/checkpoints/bert-base-cased/mrpc/20220601/rand_1._0_1_adapter_sequential_64_adapter_sequential_64" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_glue_roberta" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10088/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/text-classification" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\text-classification\run_glue_sparse.py" />
      <option name="PARAMETERS" value="--model_name_or_path roberta-base --begin 0 --prune_iterations 1 --task_name sst2 --mask_scope global --do_train yes --do_eval yes --lora_alpha 32 --lora_dropout 0.1 --lora_init bert --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --max_tokens_per_batch 0 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode bitfit --attn_option none --attn_composition add --attn_bn 10 --ffn_mode none --ffn_option none --ffn_adapter_layernorm_option none --ffn_adapter_scalar 1 --ffn_adapter_init_option bert --ffn_bn 10 --mid_dim 800 --seed 42 --unfreeze_params bias --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 20 --learning_rate 2e-4 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_steps 0 --warmup_ratio 0.06 --max_seq_length 128 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 1._lora_10_lora_10 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model accuracy --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/unstructured/roberta/checkpoints/roberta-base/mnli/20220621/snip_1._0_1_lora_none_10_lora_none_10_global --pruner snip --prune_epochs 1 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 1. --device_ids &quot;0 1 2 3 4 5 6 7&quot; --dataloader_num_workers 16" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_glue_sparse" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/text-classification" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/examples/pytorch/text-classification/run_glue_sparse.py" />
      <option name="PARAMETERS" value="--model_name_or_path roberta-base --output_dir ./ckpt --task_name cola --do_train --overwrite_output_dir --sparsity 0.5 --attn_mode adapter --attn_bn 64 --unfreeze_params ef_" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_mlm_no_trainer" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/language-modeling" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/examples/pytorch/language-modeling/run_mlm_no_trainer.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_qa (1)" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/question-answering" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/examples/pytorch/question-answering/run_qa.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_qa" type="PythonConfigurationType" factoryName="Python" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10091/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\question-answering\run_qa.py" />
      <option name="PARAMETERS" value="--model_name_or_path bert-base-cased --dataset_name squad --doc_stride 128 --max_seq_length 384 --do_train yes --do_eval yes --max_seq_length 128 --per_device_train_batch_size 48 --per_device_eval_batch_size 48 --adam_beta1 0.9 --adam_beta2 0.98 --adam_epsilon 1e-6 --attn_mode adapter --attn_option sequential --attn_composition add --attn_bn 64 --ffn_mode adapter --ffn_option sequential --ffn_adapter_layernorm_option none --ffn_adapter_scalar 1 --ffn_adapter_init_option bert --ffn_bn 64 --mid_dim 800 --seed 40 --unfreeze_params ef_ --gradient_accumulation_steps 1 --max_steps -1 --num_train_epochs 2 --learning_rate 3e-5 --lr_scheduler_type polynomial --max_grad_norm 1 --weight_decay 0.1 --warmup_steps 0 --warmup_ratio 0.06 --max_seq_length 512 --fp16 True --logging_steps 50 --save_total_limit 2 --evaluation_strategy epoch --save_strategy epoch --save_steps 5000 --eval_steps 5000 --load_best_model_at_end True --report_to none --run_name 1._adapter_64_adapter_64 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model matthews_correlation --greater_is_better True --ddp_find_unused_parameter False --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/question-answering/unstructured/bert/checkpoints/bert-base-cased/20220607/snip_1._adapter_sequential_64_adapter_sequential_64 --pruner snip --prune_epochs 1 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --sparsity 1. --device_ids &quot;0 1 2 3 4 5 6 7&quot; --dataloader_num_workers 16" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_qa_v2" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/question-answering" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\question-answering\run_qa.py" />
      <option name="PARAMETERS" value="--model_name_or_path bert-base-uncased --dataset_name squad_v2 --do_train False --do_eval --per_device_train_batch_size 12 --learning_rate 3e-5 --num_train_epochs 2 --max_seq_length 384 --doc_stride 128 --output_dir /workspace/hs/unify-parameter-efficient-tuning-master/examples/pytorch/text-classification/checkpoints/qa --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_summarization_sparse" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/summarization" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/examples/pytorch/summarization/run_summarization_sparse.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="run_xsum" type="PythonConfigurationType" factoryName="Python">
      <module name="unify-parameter-efficient-tuning-master" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="sftp://root@localhost:10092/opt/conda/bin/python3.8" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/examples/pytorch/summarization" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="E:\Project\SparseAdapter\examples\pytorch\summarization\run_summarization_sparse.py" />
      <option name="PARAMETERS" value="--dataset_name xsum --model_name_or_path facebook/bart-large --begin 0 --prune_iterations 5 --device_ids &quot;0 1 2 3 4 5 6 7&quot; --sparsity 0.5 --cache_dir /workspace/hs/unify-parameter-efficient-tuning-master/exps/checkpoints/hf_model --attn_mode prefix --attn_option concat --attn_composition add --ffn_mode adapter --ffn_option parallel --ffn_adapter_layernorm_option none --ffn_adapter_scalar 4 --ffn_adapter_init_option lora --mid_dim 800 --attn_bn 30 --ffn_bn 512 --unfreeze_params ef_ --preprocessing_num_workers 2 --max_source_length 512 --max_target_length 128 --val_max_target_length 60 --max_eval_samples 1600 --num_beams 6 --max_length 60 --min_length 10 --no_repeat_ngram_size 3 --do_train --do_eval --do_predict --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --gradient_accumulation_steps 4 --max_steps 100000 --num_train_epochs 30 --learning_rate 5e-5 --lr_scheduler_type polynomial --max_grad_norm 0.1 --weight_decay 0.01 --warmup_steps 0 --fp16 --logging_steps 100 --save_total_limit 2 --label_smoothing_factor 0.1 --evaluation_strategy steps --save_strategy steps --save_steps 3000 --eval_steps 3000 --load_best_model_at_end --report_to none --run_name xsum.20220531.xsum.am_prefix.ao_concat.fm_adapter.fo_parallel.abn30.fbn512.ac_add.fl_none.finit_lora.fs_4.unfrz_ef_.ms100000.ls0.1.warm0.wd0.01 --overwrite_output_dir True --disable_tqdm True --metric_for_best_model rouge2 --greater_is_better True --predict_with_generate --output_dir checkpoints/xsum/20220531/xsum.am_prefix.ao_concat.fm_adapter.fo_parallel.abn30.fbn512.ac_add.fl_none.finit_lora.fs_4.unfrz_ef_.ms100000.ls0.1.warm0.wd0.01" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <list>
      <item itemvalue="Python.run_qa" />
      <item itemvalue="Python.resume" />
      <item itemvalue="Python.run_glue_roberta" />
      <item itemvalue="Python.run_glue_bert" />
      <item itemvalue="Python.run_xsum" />
      <item itemvalue="Python.launch_lm" />
      <item itemvalue="Python.launch_glue" />
      <item itemvalue="Python.run_qa_v2" />
      <item itemvalue="Python.run_glue" />
      <item itemvalue="Python.run_mlm_no_trainer" />
      <item itemvalue="Python.run_glue_sparse" />
      <item itemvalue="Python.run_summarization_sparse" />
      <item itemvalue="Python.run_qa (1)" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Python.run_qa (1)" />
        <item itemvalue="Python.run_summarization_sparse" />
        <item itemvalue="Python.run_glue_sparse" />
        <item itemvalue="Python.run_mlm_no_trainer" />
        <item itemvalue="Python.run_glue" />
      </list>
    </recent_temporary>
  </component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="3bc0cb99-659d-4909-9954-7a791d56dc66" name="Changes" comment="" />
      <created>1646831352338</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1646831352338</updated>
      <workItem from="1646831354511" duration="158894000" />
      <workItem from="1647523666127" duration="112800000" />
      <workItem from="1647871502466" duration="51049000" />
      <workItem from="1648293031963" duration="55068000" />
      <workItem from="1648539542232" duration="211907000" />
      <workItem from="1649234931517" duration="138678000" />
      <workItem from="1649665347960" duration="271036000" />
      <workItem from="1650378036641" duration="5778000" />
      <workItem from="1650968914905" duration="11096000" />
      <workItem from="1651060237725" duration="30624000" />
      <workItem from="1651297076895" duration="68316000" />
      <workItem from="1651763270598" duration="8772000" />
      <workItem from="1651934583724" duration="619000" />
      <workItem from="1653131384166" duration="302517000" />
      <workItem from="1654182365669" duration="174752000" />
      <workItem from="1655614257465" duration="74497000" />
      <workItem from="1656048962332" duration="23313000" />
      <workItem from="1671248180831" duration="31104000" />
      <workItem from="1671439479598" duration="1418000" />
      <workItem from="1671544186730" duration="617000" />
      <workItem from="1671595177911" duration="140000" />
      <workItem from="1671958425529" duration="9869000" />
      <workItem from="1673187097441" duration="648000" />
      <workItem from="1678070863814" duration="605000" />
      <workItem from="1679560636949" duration="1230000" />
      <workItem from="1680450282394" duration="855000" />
      <workItem from="1680604766877" duration="17000" />
    </task>
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="XDebuggerManager">
    <breakpoint-manager>
      <breakpoints>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1666</line>
          <option name="timeStamp" value="9" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1670</line>
          <option name="timeStamp" value="10" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1512</line>
          <option name="timeStamp" value="12" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1511</line>
          <option name="timeStamp" value="14" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1710</line>
          <option name="timeStamp" value="24" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>1701</line>
          <option name="timeStamp" value="26" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>153</line>
          <option name="timeStamp" value="50" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>mock:///</url>
          <line>156</line>
          <option name="timeStamp" value="52" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/utils/dummy_pt_objects.py</url>
          <line>494</line>
          <option name="timeStamp" value="252" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/petl/petl_enc_model.py</url>
          <line>113</line>
          <option name="timeStamp" value="365" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/petl/petl_factory.py</url>
          <line>443</line>
          <option name="timeStamp" value="369" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/fmoe/layers.py</url>
          <line>194</line>
          <option name="timeStamp" value="890" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/tokenization_utils_base.py</url>
          <line>1140</line>
          <option name="timeStamp" value="953" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/tokenization_utils_base.py</url>
          <line>1139</line>
          <option name="timeStamp" value="976" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py</url>
          <line>548</line>
          <option name="timeStamp" value="1225" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer.py</url>
          <line>2430</line>
          <option name="timeStamp" value="1448" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py</url>
          <line>517</line>
          <option name="timeStamp" value="1491" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/models/roberta/modeling_roberta.py</url>
          <line>1670</line>
          <option name="timeStamp" value="1568" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer.py</url>
          <line>1835</line>
          <option name="timeStamp" value="1579" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer.py</url>
          <line>1825</line>
          <option name="timeStamp" value="1580" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer.py</url>
          <line>610</line>
          <option name="timeStamp" value="1586" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer.py</url>
          <line>1279</line>
          <option name="timeStamp" value="1588" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/src/transformers/trainer_sparse.py</url>
          <line>1483</line>
          <option name="timeStamp" value="1592" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/question-answering/run_qa.py</url>
          <line>199</line>
          <option name="timeStamp" value="1635" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/unstructured/dict_trans.py</url>
          <line>69</line>
          <option name="timeStamp" value="1658" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py</url>
          <line>445</line>
          <option name="timeStamp" value="1671" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py</url>
          <line>461</line>
          <option name="timeStamp" value="1672" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/text-classification/run_glue.py</url>
          <line>455</line>
          <option name="timeStamp" value="1674" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/examples/pytorch/language-modeling/run_mlm.py</url>
          <line>434</line>
          <option name="timeStamp" value="1675" />
        </line-breakpoint>
      </breakpoints>
      <default-breakpoints>
        <breakpoint type="python-exception">
          <properties notifyOnTerminate="true" exception="BaseException">
            <option name="notifyOnTerminate" value="true" />
          </properties>
        </breakpoint>
      </default-breakpoints>
    </breakpoint-manager>
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_resume.coverage" NAME="run_glue_resume Coverage Results" MODIFIED="1648700765219" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_pruned.coverage" NAME="run_glue_pruned Coverage Results" MODIFIED="1649924835074" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_sst2.coverage" NAME="adapter_sst2 Coverage Results" MODIFIED="1649405394745" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$compute_curve.coverage" NAME="compute_curve Coverage Results" MODIFIED="1654147805964" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_sst2_rand.coverage" NAME="adapter_sst2_rand Coverage Results" MODIFIED="1650209185608" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_clm_gpt.coverage" NAME="run_clm_gpt Coverage Results" MODIFIED="1650982706602" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_mnli_att_rand.coverage" NAME="adapter_mnli_att_rand Coverage Results" MODIFIED="1649083847109" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$compute_block.coverage" NAME="compute_block Coverage Results" MODIFIED="1655003817842" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue.coverage" NAME="run_clm Coverage Results" MODIFIED="1649222383604" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_0_1_sst2.coverage" NAME="adapter_sst2_att_rand Coverage Results" MODIFIED="1649083813459" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_clm.coverage" NAME="run_clm_split Coverage Results" MODIFIED="1650363093580" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_sst2_att.coverage" NAME="adapter_sst2_att Coverage Results" MODIFIED="1649039480978" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$resume.coverage" NAME="resume Coverage Results" MODIFIED="1653639538451" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_sst2_rand.coverage" NAME="run_sst2_rand Coverage Results" MODIFIED="1648519744054" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_sst2_snip.coverage" NAME="run_sst2_snip Coverage Results" MODIFIED="1648214146265" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$test.coverage" NAME="test Coverage Results" MODIFIED="1653398154862" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_summarization_snip_lora.coverage" NAME="run_summarization_snip_lora Coverage Results" MODIFIED="1648438703117" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_mnli_from_sst2.coverage" NAME="run_mnli_from_sst2 Coverage Results" MODIFIED="1649942690447" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$test_moe.coverage" NAME="test_moe Coverage Results" MODIFIED="1649236415632" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/src/transformers/models/gpt2" />
    <SUITE FILE_PATH="coverage/SparseAdapter$run_glue_sparse.coverage" NAME="run_glue_sparse Coverage Results" MODIFIED="1671973447679" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$test__1_.coverage" NAME="test Coverage Results" MODIFIED="1647521731851" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_clm_split.coverage" NAME="run_clm_split Coverage Results" MODIFIED="1650441179212" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_translation.coverage" NAME="run_translation Coverage Results" MODIFIED="1648299841788" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/translation" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_summarization_snip.coverage" NAME="run_summarization_snip Coverage Results" MODIFIED="1648452411617" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/summarization" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_mnli_att.coverage" NAME="adapter_mnli_att Coverage Results" MODIFIED="1648980271940" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$test_sparsity_method.coverage" NAME="test_sparsity_method Coverage Results" MODIFIED="1653202879974" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$launch.coverage" NAME="launch_lm Coverage Results" MODIFIED="1650206519007" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/distributed" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$launch_glue.coverage" NAME="launch_glue Coverage Results" MODIFIED="1651314335116" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
    <SUITE FILE_PATH="coverage/SparseAdapter$run_glue.coverage" NAME="run_glue Coverage Results" MODIFIED="1671293155015" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_summarization_rand.coverage" NAME="run_summarization_rand Coverage Results" MODIFIED="1648628835310" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/summarization" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_sst2_from_mnli.coverage" NAME="adapter_sst2_rand Coverage Results" MODIFIED="1649141910852" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$dict_trans.coverage" NAME="dict_trans Coverage Results" MODIFIED="1655195305987" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification/unstructured" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_bert.coverage" NAME="run_glue_bert Coverage Results" MODIFIED="1656052610034" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_sst2_adp.coverage" NAME="run_sst2_adp Coverage Results" MODIFIED="1651061556181" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/SparseAdapter$run_mlm_no_trainer.coverage" NAME="run_mlm_no_trainer Coverage Results" MODIFIED="1671333315639" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/language-modeling" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$compute_block__1_.coverage" NAME="compute_block Coverage Results" MODIFIED="1653982739316" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$__init__.coverage" NAME="__init__ Coverage Results" MODIFIED="1647434704175" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/Pruning" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_summarization.coverage" NAME="run_summarization Coverage Results" MODIFIED="1647844554246" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/summarization" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_qa.coverage" NAME="run_qa Coverage Results" MODIFIED="1654656443259" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_mnli.coverage" NAME="adapter_mnli_rand Coverage Results" MODIFIED="1649136071674" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_mnli_adp.coverage" NAME="launch_glue Coverage Results" MODIFIED="1654079587205" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/distributed" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$adapter_mnli_rand.coverage" NAME="adapter_mnli_rand Coverage Results" MODIFIED="1649314220242" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_roberta.coverage" NAME="run_glue_roberta Coverage Results" MODIFIED="1656099782515" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$gather_data.coverage" NAME="gather_data Coverage Results" MODIFIED="1649733226628" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/SparseAdapter$run_summarization_sparse.coverage" NAME="run_summarization_sparse Coverage Results" MODIFIED="1671974461176" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/summarization" />
    <SUITE FILE_PATH="coverage/SparseAdapter$run_qa__1_.coverage" NAME="run_qa (1) Coverage Results" MODIFIED="1671974595876" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/question-answering" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_translation_rand.coverage" NAME="run_translation_rand Coverage Results" MODIFIED="1648361912605" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/translation" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_1_.coverage" NAME="run_glue(1) Coverage Results" MODIFIED="1647522081401" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$layers.coverage" NAME="layers Coverage Results" MODIFIED="1649225050474" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/src/transformers/fmoe" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_sst2_mam.coverage" NAME="run_xsum Coverage Results" MODIFIED="1654154376944" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/summarization" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_translation_pruned.coverage" NAME="run_translation_pruned Coverage Results" MODIFIED="1648372367940" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_prunedsnip.coverage" NAME="run_glue_prunedsnip Coverage Results" MODIFIED="1647759646106" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$run_glue_check.coverage" NAME="run_glue_check Coverage Results" MODIFIED="1647757508442" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
    <SUITE FILE_PATH="coverage/unify_parameter_efficient_tuning_master$compute_params.coverage" NAME="compute_params Coverage Results" MODIFIED="1656054856081" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/examples/pytorch/text-classification" />
  </component>
</project>